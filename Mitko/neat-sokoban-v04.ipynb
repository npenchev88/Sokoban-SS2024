{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8421c894",
   "metadata": {},
   "source": [
    "How to create the environment (replace neat_test4 with your env name):\n",
    "\n",
    "- conda create -n neat_test4 python=3.10 gym ipykernel pyglet\n",
    "- conda activate neat_test4\n",
    "- pip install neat-python\n",
    "- pip install -e \"<path_to_gym_location>\\gym-sokoban\"\n",
    "- python -m ipykernel install --user --name neat_test4 --display-name \"Python (neat_test4)\"\n",
    "- pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ed788",
   "metadata": {},
   "source": [
    "### Initial setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d071e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:41:52.355762Z",
     "start_time": "2024-06-28T13:41:51.679736Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "from pyglet import clock\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from neat.reporting import StdOutReporter\n",
    "import random\n",
    "import visualize\n",
    "import graphviz\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411076a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5391c98b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:41:52.403760Z",
     "start_time": "2024-06-28T13:41:52.389761Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6594b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:41:52.800315Z",
     "start_time": "2024-06-28T13:41:52.778316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom reporter class\n",
    "class CustomReporter(StdOutReporter):\n",
    "    def __init__(self, show_species_detail, config_filename):\n",
    "        super().__init__(show_species_detail)\n",
    "        self.start_time = time.time()\n",
    "        self.config_filename = config_filename\n",
    "    \n",
    "    def end(self):\n",
    "        runtime = time.time() - self.start_time\n",
    "        logging.info(f'Total runtime: {runtime:.2f} seconds')\n",
    "    \n",
    "    def post_evaluate(self, config, population, species_set, best_genome):\n",
    "        super().post_evaluate(config, population, species_set, best_genome)\n",
    "        \n",
    "        # Log population's average fitness\n",
    "        total_fitness = sum(genome.fitness for genome in population.values())\n",
    "        avg_fitness = total_fitness / len(population)\n",
    "        logging.info(f'Population\\'s average fitness: {avg_fitness}')\n",
    "        \n",
    "        # Log adjusted fitness score\n",
    "        adjusted_fitness = []\n",
    "        for species_id, species in species_set.species.items():\n",
    "            for genome_id in species.members:\n",
    "                genome = population[genome_id]\n",
    "                adjusted_fitness.append(genome.fitness / len(species.members))\n",
    "        avg_adjusted_fitness = sum(adjusted_fitness) / len(adjusted_fitness)\n",
    "        logging.info(f'Population\\'s average adjusted fitness: {avg_adjusted_fitness}')\n",
    "        \n",
    "        # Log best genome information\n",
    "        logging.info(f'\\nBest genome:\\nKey: {best_genome.key}\\nFitness: {best_genome.fitness}')\n",
    "        logging.info(f'Nodes:')\n",
    "        for node_key, node in best_genome.nodes.items():\n",
    "            logging.info(f'\\t{node_key} {node}')\n",
    "        logging.info(f'Connections:')\n",
    "        for conn_key, conn in best_genome.connections.items():\n",
    "            logging.info(f'\\t{conn_key} {conn}')\n",
    "        \n",
    "        # Log configuration file content\n",
    "        if self.config_filename:\n",
    "            try:\n",
    "                with open(self.config_filename, 'r') as f:\n",
    "                    config_content = f.read()\n",
    "                    logging.info(f'Config File:\\n{config_content}')\n",
    "            except FileNotFoundError:\n",
    "                logging.warning(f'Config file \"{self.config_filename}\" not found.')\n",
    "\n",
    "        # Log timestamp\n",
    "        logging.info(f'Timestamp: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9a3368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:41:53.352382Z",
     "start_time": "2024-06-28T13:41:53.346385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(filename='neat_log.txt', level=logging.INFO, format='%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec30fc8",
   "metadata": {},
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8110c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:42:00.374363Z",
     "start_time": "2024-06-28T13:41:59.108299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration.\n",
    "config_filename = 'config-feedforward_v04'\n",
    "config = neat.Config(neat.DefaultGenome, \n",
    "                     neat.DefaultReproduction, \n",
    "                     neat.DefaultSpeciesSet, \n",
    "                     neat.DefaultStagnation, \n",
    "                     config_filename)\n",
    "\n",
    "\n",
    "# Check if a checkpoint exists\n",
    "checkpoint_file = r'D:\\Education\\AI\\Machine_Learning_Practice\\Summer School 2024\\Sokoban-SS2024\\NEAT\\run_config_04\\empty'  # Replace with your checkpoint filename\n",
    "\n",
    "if os.path.isfile(checkpoint_file):\n",
    "    # Load the checkpoint\n",
    "    p = neat.Checkpointer.restore_checkpoint(checkpoint_file)\n",
    "else:\n",
    "    # Create the population if no checkpoint exists\n",
    "    p = neat.Population(config)\n",
    "    \n",
    "\n",
    "# Add reporters to show progress in the terminal and log to file.\n",
    "p.add_reporter(neat.StdOutReporter(True))\n",
    "custom_reporter = CustomReporter(True, config_filename)\n",
    "p.add_reporter(custom_reporter)\n",
    "stats = neat.StatisticsReporter()\n",
    "p.add_reporter(stats)\n",
    "p.add_reporter(neat.Checkpointer(1, filename_prefix='neat-checkpoint-v04-'))\n",
    "\n",
    "file_name = 'winner_test_04.pkl'\n",
    "\n",
    "\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "min_reward = -10\n",
    "\n",
    "# param used to mutate a step\n",
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27ad5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85bdb56a",
   "metadata": {},
   "source": [
    "### Classes and methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15347fe",
   "metadata": {},
   "source": [
    "#### Preprocessing inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba239519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:42:01.412940Z",
     "start_time": "2024-06-28T13:42:01.394956Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_observation(environment, obs):\n",
    "        \n",
    "    # Convert the observation to RGB frame or custom observation\n",
    "    arr_walls, arr_goals, arr_boxes, arr_player = environment.render(mode='raw')\n",
    "\n",
    "    # Initialize the combined array with walls (1s)\n",
    "    combined = np.ones_like(arr_walls)\n",
    "    \n",
    "    # Set empty fields (0s)\n",
    "    combined[arr_walls == 0] = 0\n",
    "    \n",
    "    # Set targets (3s)\n",
    "    combined[arr_goals == 1] = 3\n",
    "    \n",
    "    # Set boxes (2s)\n",
    "    combined[arr_boxes == 1] = 2\n",
    "    \n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(arr_boxes == 1) & (arr_goals == 1)] = 4\n",
    "    \n",
    "    # Set player position (5s)\n",
    "    combined[arr_player == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "#     print(\"Flat array: \", flat_array)\n",
    "#     print(\"Flat array shape: \", flat_array.shape)\n",
    "\n",
    "    # Output the flattened array\n",
    "    return flat_array\n",
    "\n",
    "\n",
    "\n",
    "def process_state(state):\n",
    "# Processes the initial state of env.reset()\n",
    "\n",
    "\n",
    "    # Initialize the combined array with walls (0s)\n",
    "    combined = np.ones_like(state[0])\n",
    "    \n",
    "    # Set empty fields (1s)\n",
    "    combined[state[0] == 0] = 0\n",
    "\n",
    "    # Set targets (3s)\n",
    "    combined[state[1] == 1] = 3\n",
    "\n",
    "    # Set boxes (2s)\n",
    "    combined[state[2] == 1] = 2\n",
    "\n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(state[2] == 1) & (state[1] == 1)] = 4\n",
    "\n",
    "    # Set player position (5s)\n",
    "    combined[state[3] == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "#     print(\"Flat array: \", flat_array)\n",
    "#     print(\"Flat array shape: \", flat_array.shape)\n",
    "\n",
    "    # Output the flattened array\n",
    "    return flat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2332ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:42:02.016459Z",
     "start_time": "2024-06-28T13:42:01.999942Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_action(output):\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13995391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2f531e",
   "metadata": {},
   "source": [
    "### Run Neat logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667d293",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-28T13:42:03.013Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test4\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test4\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test4\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:199: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` should be `(obs, info)` by default, , where `obs` is a observation and `info` is a dictionary containing additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test4\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test4\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population's average fitness: -17.50440 stdev: 4.25161\n",
      "Best fitness: -3.80000 - size: (9, 441) - species 1 - id 348\n",
      "Population's average fitness: -17.50440 stdev: 4.25161\n",
      "Best fitness: -3.80000 - size: (9, 441) - species 1 - id 348\n",
      "Average adjusted fitness: 0.154\n",
      "Average adjusted fitness: 0.154\n",
      "Mean genetic distance 1.675, standard deviation 0.327\n",
      "Mean genetic distance 1.675, standard deviation 0.327\n",
      "Population of 500 members in 3 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0   497     -3.8    0.154     0\n",
      "     2    0     1       --       --     0\n",
      "     3    0     2       --       --     0\n",
      "Total extinctions: 0\n",
      "Generation time: 817.721 sec\n",
      "Population of 500 members in 3 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "     1    0   497     -3.8    0.154     0\n",
      "     2    0     1       --       --     0\n",
      "     3    0     2       --       --     0\n",
      "Total extinctions: 0\n",
      "Generation time: 817.721 sec\n",
      "Saving checkpoint to neat-checkpoint-v04-0\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n",
      "\n",
      " ****** Running generation 1 ****** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the game\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "\n",
    "# # OPTIONAL\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "\n",
    "    global num_episodes, timesteps_per_episode, current_episode, current_timestep, min_reward\n",
    "\n",
    "    # FOR EACH GENOME\n",
    "    for genome_id, genome in genomes:\n",
    "               \n",
    "        # generate the neural network based on the config provided\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    \n",
    "        # define the initial fitness of the genome\n",
    "        genome.fitness = 0.0\n",
    "    \n",
    "        # define episodes rewards (list) idea is to keep the fitness scores of all episodes and take the max\n",
    "        episodes_rewards = []\n",
    "        \n",
    "        # FOR EACH EPISODE\n",
    "        for episode in range(num_episodes):\n",
    "            \n",
    "            # Episode reward = 0  \n",
    "            ep_reward = 0\n",
    "            \n",
    "            # reset the game state to the initial phase\n",
    "            initial_state = env.reset()\n",
    "\n",
    "            # map inputs suitable for the Neural Network (initial state of the game as flatten array, e.g. with length 49, created by the initial 7x7 grid)\n",
    "            # used as an input layer in the Neural Network\n",
    "            initial_inputs = process_state(initial_state)\n",
    "            \n",
    "            game_state_after_step = initial_inputs\n",
    "            \n",
    "            # FOR EACH STEP\n",
    "            for step in range(timesteps_per_episode):\n",
    "                \n",
    "               \n",
    "                # calculate probabilities for each output to be selected\n",
    "                action_prob = net.activate(game_state_after_step)\n",
    "                \n",
    "                # select the action, based on the output's probabilities of being selected\n",
    "                action = map_action(action_prob)\n",
    "                \n",
    "                # ADD CUSTOM MUTATION IN THE STEPS (at a random event, the alg could chose a random step)\n",
    "                \n",
    "                if random.random() < epsilon:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # select the action, based on the output's probabilities of being selected\n",
    "                    action = map_action(action_prob)\n",
    "                \n",
    "#                 # RANDOM ACTION (replace with the genome)\n",
    "#                 action = env.action_space.sample()\n",
    "\n",
    "                # make the move in the game and output game state + info + reward\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                \n",
    "#                 # TODO (MAYBE) !!!! Adjust the fitness function\n",
    "                \n",
    "#                 # 1) USE THE info to extract information about the move and change the reward accordingly\n",
    "                \n",
    "                # penalizes the passiveness of the player; rewards movement of boxes more\n",
    "                if not info[\"action.moved_player\"]:\n",
    "                    reward = -0.5                \n",
    "                elif info[\"action.moved_box\"]:\n",
    "                    reward = 0.2\n",
    "#                 elif ....\n",
    "                \n",
    "                game_state_after_step = process_observation(environment=env, obs=observation)\n",
    "\n",
    "                # IMAGE STUFF\n",
    "                image = env.render(mode='rgb_array')\n",
    "                viewer.render(image)\n",
    "\n",
    "#                 # PRINT INFO\n",
    "                logging.info(f'Population\\'s steps info: {(ACTION_LOOKUP[action], reward, done, info)}')\n",
    "\n",
    "                # POPULATE THE Episode reward +=\n",
    "                # if the game didn't end on this step\n",
    "                if not done:\n",
    "                    ep_reward += reward\n",
    "                    current_timestep += 1\n",
    "                    \n",
    "                # if the game ended\n",
    "                else:\n",
    "#                     current_timestep = 0\n",
    "#                     current_episode += 1\n",
    "                    print(f\"I BEAT THE STUPID GAME!!! Happend on step {current_timestep}\")\n",
    "                    break\n",
    "    \n",
    "                    # OR BREAK\n",
    "\n",
    "            # add the accumulated rewards for this episode into a list (episodes_rewards)   \n",
    "            episodes_rewards.append(ep_reward)\n",
    "\n",
    "        # choose the best performance on an episode for the genome\n",
    "        genome.fitness = max(episodes_rewards)\n",
    "\n",
    "#         print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "        \n",
    "\n",
    "\n",
    "# Run until a solution is found. The number indicates the max number of generations to be produced\n",
    "winner = p.run(eval_genomes, 25)\n",
    "\n",
    "\n",
    "# Display the winning genome.\n",
    "print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# SAVE THE WINNER GENOME\n",
    "with open(\"winner.pkl\", \"wb\") as f:\n",
    "    pickle.dump(winner, f)\n",
    "\n",
    "# Show output of the most fit genome against training data.\n",
    "print('\\nOutput:')\n",
    "winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "# Save the winner\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(winner, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6082cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:34:06.853784Z",
     "start_time": "2024-06-28T05:34:06.061859Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize.plot_stats(stats, ylog=False, view=True)\n",
    "visualize.plot_species(stats, view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14ed26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T06:37:58.613943Z",
     "start_time": "2024-06-28T06:37:58.404149Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize.draw_net(config=config, genome=winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de306002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674e73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086be0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca1de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daca4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180f5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238db659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127d1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e834c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53154976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6709c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a3735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:37:55.958605Z",
     "start_time": "2024-06-27T16:37:55.936867Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "\n",
    "# Load configuration.\n",
    "config_filename = 'config-feedforward_v01'\n",
    "config = neat.Config(neat.DefaultGenome, \n",
    "                     neat.DefaultReproduction, \n",
    "                     neat.DefaultSpeciesSet, \n",
    "                     neat.DefaultStagnation, \n",
    "                     config_filename)\n",
    "\n",
    "config.genome_config.add_node_mutation_prob = 0.03\n",
    "config.genome_config.add_connection_mutation_prob = 0.05\n",
    "\n",
    "# Print the parsed parameters to debug\n",
    "print(\"Initial connection type:\", config.genome_config.initial_connection)\n",
    "print(\"Allowed connectivity options:\", config.genome_config.allowed_connectivity)\n",
    "print(\"Activation options:\", config.genome_config.activation_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393643a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c937403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30815687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7995ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1ed23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ded82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae5223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ce5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4eb568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d191f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646a9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91215838",
   "metadata": {},
   "source": [
    "### ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8599",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-26T13:39:04.976Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from neat.reporting import StdOutReporter\n",
    "\n",
    "# Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='neat_log.txt', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# Custom reporter class\n",
    "class CustomReporter(StdOutReporter):\n",
    "    def __init__(self, show_species_detail):\n",
    "        super().__init__(show_species_detail)\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def end(self):\n",
    "        runtime = time.time() - self.start_time\n",
    "        logging.info(f'Total runtime: {runtime:.2f} seconds')\n",
    "\n",
    "    def post_evaluate(self, config, population, species_set, best_genome):\n",
    "        super().post_evaluate(config, population, species_set, best_genome)\n",
    "        \n",
    "        # Log population's average fitness\n",
    "        total_fitness = sum(genome.fitness for genome in population.values())\n",
    "        avg_fitness = total_fitness / len(population)\n",
    "        logging.info(f'Population\\'s average fitness: {avg_fitness}')\n",
    "        \n",
    "        # Log adjusted fitness score\n",
    "        adjusted_fitness = []\n",
    "        for species_id, species in species_set.species.items():\n",
    "            for genome_id in species.members:\n",
    "                genome = population[genome_id]\n",
    "                adjusted_fitness.append(genome.fitness / len(species.members))\n",
    "        avg_adjusted_fitness = sum(adjusted_fitness) / len(adjusted_fitness)\n",
    "        logging.info(f'Population\\'s average adjusted fitness: {avg_adjusted_fitness}')\n",
    "        \n",
    "        # Log best genome information\n",
    "        logging.info(f'\\nBest genome:\\nKey: {best_genome.key}\\nFitness: {best_genome.fitness}')\n",
    "        logging.info(f'Nodes:')\n",
    "        for node_key, node in best_genome.nodes.items():\n",
    "            logging.info(f'\\t{node_key} {node}')\n",
    "        logging.info(f'Connections:')\n",
    "        for conn_key, conn in best_genome.connections.items():\n",
    "            logging.info(f'\\t{conn_key} {conn}')\n",
    "        logging.info(f'Timestamp: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "\n",
    "def process_observation(environment, obs):\n",
    "    # Convert the observation to RGB frame or custom observation\n",
    "    arr_walls, arr_goals, arr_boxes, arr_player = environment.render(mode='raw')\n",
    "\n",
    "    # Initialize the combined array with walls (1s)\n",
    "    combined = np.ones_like(arr_walls)\n",
    "    \n",
    "    # Set empty fields (0s)\n",
    "    combined[arr_walls == 0] = 0\n",
    "    \n",
    "    # Set targets (3s)\n",
    "    combined[arr_goals == 1] = 3\n",
    "    \n",
    "    # Set boxes (2s)\n",
    "    combined[arr_boxes == 1] = 2\n",
    "    \n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(arr_boxes == 1) & (arr_goals == 1)] = 4\n",
    "    \n",
    "    # Set player position (5s)\n",
    "    combined[arr_player == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "    return flat_array\n",
    "\n",
    "\n",
    "def process_state(state):\n",
    "    # Processes the initial state of env.reset()\n",
    "\n",
    "    # Initialize the combined array with walls (0s)\n",
    "    combined = np.ones_like(state[0])\n",
    "    \n",
    "    # Set empty fields (1s)\n",
    "    combined[state[0] == 0] = 0\n",
    "\n",
    "    # Set targets (3s)\n",
    "    combined[state[1] == 1] = 3\n",
    "\n",
    "    # Set boxes (2s)\n",
    "    combined[state[2] == 1] = 2\n",
    "\n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(state[2] == 1) & (state[1] == 1)] = 4\n",
    "\n",
    "    # Set player position (5s)\n",
    "    combined[state[3] == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "    return flat_array\n",
    "\n",
    "\n",
    "# Start the game\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "env.reset()\n",
    "\n",
    "# Optional viewer setup\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "def map_action(action_prob):\n",
    "    return np.argmax(action_prob)\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    global num_episodes, timesteps_per_episode\n",
    "\n",
    "    # For each genome\n",
    "    for genome_id, genome in genomes:\n",
    "        # Generate the neural network based on the config provided\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    \n",
    "        # Define the initial fitness of the genome\n",
    "        genome.fitness = 0.0\n",
    "    \n",
    "        # Define episodes rewards (list) idea is to keep the fitness scores of all episodes and take the max\n",
    "        episodes_rewards = []\n",
    "        \n",
    "        # For each episode\n",
    "        for episode in range(num_episodes):\n",
    "            # Episode reward = 0  \n",
    "            ep_reward = 0\n",
    "            \n",
    "            # Reset the game state to the initial phase\n",
    "            initial_state = env.reset()\n",
    "\n",
    "            # Map inputs suitable for the Neural Network (initial state of the game as flatten array, e.g. with length 49, created by the initial 7x7 grid)\n",
    "            # Used as an input layer in the Neural Network\n",
    "            initial_inputs = process_state(initial_state)\n",
    "            \n",
    "            game_state_after_step = initial_inputs\n",
    "            \n",
    "            # For each step\n",
    "            for step in range(timesteps_per_episode):\n",
    "                # Calculate probabilities for each output to be selected\n",
    "                action_prob = net.activate(game_state_after_step)\n",
    "                \n",
    "                # Select the action, based on the output's probabilities of being selected\n",
    "                action = map_action(action_prob)\n",
    "                \n",
    "                # Make the move in the game and output game state + info + reward\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                \n",
    "                game_state_after_step = process_observation(environment=env, obs=observation)\n",
    "\n",
    "                # Image stuff\n",
    "                image = env.render(mode='rgb_array')\n",
    "                viewer.render(image)\n",
    "\n",
    "                # Print info\n",
    "                print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "                # Populate the episode reward\n",
    "                if not done:\n",
    "                    ep_reward += reward\n",
    "                else:\n",
    "                    print(f\"Game finished in {step+1} steps\")\n",
    "                    break\n",
    "    \n",
    "            # Add the accumulated rewards for this episode into a list (episodes_rewards)   \n",
    "            episodes_rewards.append(ep_reward)\n",
    "\n",
    "        # Choose the best performance on an episode for the genome\n",
    "        genome.fitness = max(episodes_rewards)\n",
    "\n",
    "        print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "\n",
    "# Load configuration.\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     'config-feedforward')\n",
    "\n",
    "# Create the population, which is the top-level object for a NEAT run.\n",
    "p = neat.Population(config)\n",
    "\n",
    "# Add a stdout reporter to show progress in the terminal.\n",
    "p.add_reporter(neat.StdOutReporter(True))\n",
    "p.add_reporter(CustomReporter(True))\n",
    "p.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "# Run until a solution is found. The number indicates the max number of generations to be produced\n",
    "winner = p.run(eval_genomes, 5)\n",
    "\n",
    "# Display the winning genome.\n",
    "print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# Show output of the most fit genome against training data.\n",
    "print('\\nOutput:')\n",
    "winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "# Start the Pyglet event loop to keep the window open\n",
    "pyglet.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1539b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98769e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4aca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e221f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325e476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525257b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23999afe",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd48847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the game\n",
    "\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "\n",
    "# # OPTIONAL\n",
    "\n",
    "# viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "\n",
    "# ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "min_reward = -10\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config)\n",
    "# FOR EACH GENOME\n",
    "    for genome_id, genome in genomes:\n",
    "        \n",
    "        env = gym.make()\n",
    "    # net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    # DEF INITIAL GENOME FITNESS = 0\n",
    "    \n",
    "    \n",
    "    # EPISODES REWARDS = [] IDEA IS TO KEEP THE FITNESS SCORES OF ALL EPISODES AND THEN TAKE THE MAX\n",
    "    \n",
    "    # FOR EACH EPISODE\n",
    "        # Episode reward = 0  \n",
    "        # env.reset()\n",
    "            \n",
    "        # FOR EACH STEP\n",
    "            # ACTION - GENERATED BY THE GENOME\n",
    "            # RANDOM ACTION\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "            # MAKE THE MOVE IN THE GAME\n",
    "            # OUTPUT GAME STATE AFTER THE STEP WITH INFO + REWARD            \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            # IMAGE STUFF\n",
    "            image = env.render(mode='rgb_array')\n",
    "            viewer.render(image)\n",
    "            \n",
    "            # PRINT INFO\n",
    "            print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "            # POPULATE THE Episode reward +=\n",
    "            # if not done:\n",
    "                # reward += MIN REWARD\n",
    "                # current_timestep += 1\n",
    "\n",
    "            # if done:\n",
    "                # current_timestep = 0\n",
    "                # current_episode += 1\n",
    "\n",
    "                # OR BREAK\n",
    "\n",
    "        # EPISODES REWARDS APPEND episode reward   \n",
    "        \n",
    "    \n",
    "    # GENOME.FITNESS = max(EPISODE REWARDS)        \n",
    "                \n",
    "\n",
    "        \n",
    "\n",
    "# # Load configuration.\n",
    "# config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "#                      neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "#                      'config-feedforward')\n",
    "\n",
    "# # Create the population, which is the top-level object for a NEAT run.\n",
    "# p = neat.Population(config)\n",
    "\n",
    "# # Add a stdout reporter to show progress in the terminal.\n",
    "# p.add_reporter(neat.StdOutReporter(False))\n",
    "\n",
    "# # Run until a solution is found.\n",
    "# winner = p.run(eval_genomes, 5)\n",
    "\n",
    "# # Display the winning genome.\n",
    "# print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# # Show output of the most fit genome against training data.\n",
    "# print('\\nOutput:')\n",
    "# winner_net = neat.nn.FeedForwardNetwork.create(winner, config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752210af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c83cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90653981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932315a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82e8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a46f3fa4",
   "metadata": {},
   "source": [
    "### Game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c18863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "from pyglet import clock\n",
    "import numpy as np\n",
    "\n",
    "## Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)\n",
    "\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "print(\"Room Fixed\")\n",
    "print(env.room_fixed)\n",
    "print(type(env.room_fixed))\n",
    "print(env.room_fixed.shape)\n",
    "print()\n",
    "print(env.room_state)\n",
    "print()\n",
    "print(env.box_mapping)\n",
    "print()\n",
    "\n",
    "\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 2\n",
    "timesteps_per_episode = 100\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "def update_environment(dt):\n",
    "    global current_episode, current_timestep, num_episodes, timesteps_per_episode\n",
    "\n",
    "    if current_episode < num_episodes:\n",
    "        if current_timestep < timesteps_per_episode:\n",
    "            # RANDOM ACTION\n",
    "            action = env.action_space.sample()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            \n",
    "            image = env.render(mode='rgb_array')\n",
    "            viewer.render(image)\n",
    "\n",
    "            print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode finished after {current_timestep + 1} timesteps\")\n",
    "                current_timestep = 0\n",
    "                current_episode += 1\n",
    "                env.reset()\n",
    "            else:\n",
    "                current_timestep += 1\n",
    "        else:\n",
    "            current_episode += 1\n",
    "            current_timestep = 0\n",
    "            env.reset()\n",
    "    else:\n",
    "        print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "\n",
    "# Increase the frequency to match rendering needs (e.g., 60Hz)\n",
    "clock.schedule_interval(update_environment, 1/60.0)\n",
    "\n",
    "pyglet.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6a928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b6ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59de40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb8309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neat_test4]",
   "language": "python",
   "name": "conda-env-.conda-neat_test4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
