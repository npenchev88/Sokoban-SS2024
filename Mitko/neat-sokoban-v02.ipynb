{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd82f308",
   "metadata": {},
   "source": [
    "How to create the environment (replace neat_test4 with your env name):\n",
    "\n",
    "- conda create -n neat_test4 python=3.10 gym ipykernel pyglet\n",
    "- conda activate neat_test4\n",
    "- pip install neat-python\n",
    "- pip install -e \"<path_to_gym_location>\\gym-sokoban\"\n",
    "- python -m ipykernel install --user --name neat_test4 --display-name \"Python (neat_test4)\"\n",
    "- pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ed788",
   "metadata": {},
   "source": [
    "### Initial setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d071e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:20.336571Z",
     "start_time": "2024-06-28T13:40:19.755685Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "from pyglet import clock\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from neat.reporting import StdOutReporter\n",
    "import random\n",
    "import visualize\n",
    "import graphviz\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3dfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14eb0bb",
   "metadata": {},
   "source": [
    "### Classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d693fe25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:20.950284Z",
     "start_time": "2024-06-28T13:40:20.943301Z"
    }
   },
   "outputs": [],
   "source": [
    "## Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a352e4f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:21.406513Z",
     "start_time": "2024-06-28T13:40:21.388764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom reporter class\n",
    "class CustomReporter(StdOutReporter):\n",
    "    def __init__(self, show_species_detail, config_filename):\n",
    "        super().__init__(show_species_detail)\n",
    "        self.start_time = time.time()\n",
    "        self.config_filename = config_filename\n",
    "    \n",
    "    def end(self):\n",
    "        runtime = time.time() - self.start_time\n",
    "        logging.info(f'Total runtime: {runtime:.2f} seconds')\n",
    "    \n",
    "    def post_evaluate(self, config, population, species_set, best_genome):\n",
    "        super().post_evaluate(config, population, species_set, best_genome)\n",
    "        \n",
    "        # Log population's average fitness\n",
    "        total_fitness = sum(genome.fitness for genome in population.values())\n",
    "        avg_fitness = total_fitness / len(population)\n",
    "        logging.info(f'Population\\'s average fitness: {avg_fitness}')\n",
    "        \n",
    "        # Log adjusted fitness score\n",
    "        adjusted_fitness = []\n",
    "        for species_id, species in species_set.species.items():\n",
    "            for genome_id in species.members:\n",
    "                genome = population[genome_id]\n",
    "                adjusted_fitness.append(genome.fitness / len(species.members))\n",
    "        avg_adjusted_fitness = sum(adjusted_fitness) / len(adjusted_fitness)\n",
    "        logging.info(f'Population\\'s average adjusted fitness: {avg_adjusted_fitness}')\n",
    "        \n",
    "        # Log best genome information\n",
    "        logging.info(f'\\nBest genome:\\nKey: {best_genome.key}\\nFitness: {best_genome.fitness}')\n",
    "        logging.info(f'Nodes:')\n",
    "        for node_key, node in best_genome.nodes.items():\n",
    "            logging.info(f'\\t{node_key} {node}')\n",
    "        logging.info(f'Connections:')\n",
    "        for conn_key, conn in best_genome.connections.items():\n",
    "            logging.info(f'\\t{conn_key} {conn}')\n",
    "        \n",
    "        # Log configuration file content\n",
    "        if self.config_filename:\n",
    "            try:\n",
    "                with open(self.config_filename, 'r') as f:\n",
    "                    config_content = f.read()\n",
    "                    logging.info(f'Config File:\\n{config_content}')\n",
    "            except FileNotFoundError:\n",
    "                logging.warning(f'Config file \"{self.config_filename}\" not found.')\n",
    "\n",
    "        # Log timestamp\n",
    "        logging.info(f'Timestamp: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe31d3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:21.831582Z",
     "start_time": "2024-06-28T13:40:21.824073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.basicConfig(filename='neat_log.txt', level=logging.INFO, format='%(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec30fc8",
   "metadata": {},
   "source": [
    "#### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8110c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:23.419947Z",
     "start_time": "2024-06-28T13:40:23.004060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration.\n",
    "config_filename = 'config-feedforward_v02'\n",
    "config = neat.Config(neat.DefaultGenome, \n",
    "                     neat.DefaultReproduction, \n",
    "                     neat.DefaultSpeciesSet, \n",
    "                     neat.DefaultStagnation, \n",
    "                     config_filename)\n",
    "\n",
    "\n",
    "# Check if a checkpoint exists\n",
    "checkpoint_file = r'D:\\Education\\AI\\Machine_Learning_Practice\\Summer School 2024\\Sokoban-SS2024\\NEAT\\run1_config_02\\neat-checkpoint-48'  # Replace with your checkpoint filename\n",
    "\n",
    "if os.path.isfile(checkpoint_file):\n",
    "    # Load the checkpoint\n",
    "    p = neat.Checkpointer.restore_checkpoint(checkpoint_file)\n",
    "else:\n",
    "    # Create the population if no checkpoint exists\n",
    "    p = neat.Population(config)\n",
    "\n",
    "# Add reporters to show progress in the terminal and log to file.\n",
    "p.add_reporter(neat.StdOutReporter(True))\n",
    "custom_reporter = CustomReporter(True, config_filename)\n",
    "p.add_reporter(custom_reporter)\n",
    "stats = neat.StatisticsReporter()\n",
    "p.add_reporter(stats)\n",
    "p.add_reporter(neat.Checkpointer(1, filename_prefix='neat-checkpoint-v02-'))\n",
    "\n",
    "file_name = 'winner_test_02.pkl'\n",
    "\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "min_reward = -10\n",
    "\n",
    "# param used to mutate a step\n",
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27ad5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15347fe",
   "metadata": {},
   "source": [
    "#### Preprocessing inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba239519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:32.636310Z",
     "start_time": "2024-06-28T13:40:32.629309Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_observation(environment, obs):\n",
    "        \n",
    "    # Convert the observation to RGB frame or custom observation\n",
    "    arr_walls, arr_goals, arr_boxes, arr_player = environment.render(mode='raw')\n",
    "\n",
    "    # Initialize the combined array with walls (1s)\n",
    "    combined = np.ones_like(arr_walls)\n",
    "    \n",
    "    # Set empty fields (0s)\n",
    "    combined[arr_walls == 0] = 0\n",
    "    \n",
    "    # Set targets (3s)\n",
    "    combined[arr_goals == 1] = 3\n",
    "    \n",
    "    # Set boxes (2s)\n",
    "    combined[arr_boxes == 1] = 2\n",
    "    \n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(arr_boxes == 1) & (arr_goals == 1)] = 4\n",
    "    \n",
    "    # Set player position (5s)\n",
    "    combined[arr_player == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "#     print(\"Flat array: \", flat_array)\n",
    "#     print(\"Flat array shape: \", flat_array.shape)\n",
    "\n",
    "    # Output the flattened array\n",
    "    return flat_array\n",
    "\n",
    "\n",
    "\n",
    "def process_state(state):\n",
    "# Processes the initial state of env.reset()\n",
    "\n",
    "\n",
    "    # Initialize the combined array with walls (0s)\n",
    "    combined = np.ones_like(state[0])\n",
    "    \n",
    "    # Set empty fields (1s)\n",
    "    combined[state[0] == 0] = 0\n",
    "\n",
    "    # Set targets (3s)\n",
    "    combined[state[1] == 1] = 3\n",
    "\n",
    "    # Set boxes (2s)\n",
    "    combined[state[2] == 1] = 2\n",
    "\n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(state[2] == 1) & (state[1] == 1)] = 4\n",
    "\n",
    "    # Set player position (5s)\n",
    "    combined[state[3] == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "#     print(\"Flat array: \", flat_array)\n",
    "#     print(\"Flat array shape: \", flat_array.shape)\n",
    "\n",
    "    # Output the flattened array\n",
    "    return flat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2332ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T13:40:33.471087Z",
     "start_time": "2024-06-28T13:40:33.456215Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_action(output):\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13995391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b2f531e",
   "metadata": {},
   "source": [
    "### Run Neat logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667d293",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-28T13:40:34.463Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:199: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` should be `(obs, info)` by default, , where `obs` is a observation and `info` is a dictionary containing additional information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 48 ****** \n",
      "\n",
      "\n",
      " ****** Running generation 48 ****** \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "C:\\Users\\Mitko\\.conda\\envs\\neat_test\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population's average fitness: -11.49613 stdev: 6.81270\n",
      "Best fitness: -3.40000 - size: (13, 378) - species 439 - id 6869\n",
      "Population's average fitness: -11.49613 stdev: 6.81270\n",
      "Best fitness: -3.40000 - size: (13, 378) - species 439 - id 6869\n",
      "\n",
      "Species 354 with 5 members is stagnated: removing it\n",
      "\n",
      "Species 354 with 5 members is stagnated: removing it\n",
      "Average adjusted fitness: 0.451\n",
      "Average adjusted fitness: 0.451\n",
      "Mean genetic distance 3.741, standard deviation 0.479\n",
      "Mean genetic distance 3.741, standard deviation 0.479\n",
      "Population of 539 members in 163 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "   285   22     3     -3.4    0.536     7\n",
      "   320   17     2    -18.4    0.096     7\n",
      "   324   17     4     -4.0    0.681     9\n",
      "   331   16     4     -4.4    0.635     5\n",
      "   340   15     3     -6.4    0.434     9\n",
      "   342   15     2    -16.7    0.145     0\n",
      "   346   15     4     -4.0    0.786     8\n",
      "   356   14     2    -18.4    0.048     0\n",
      "   361   14     3    -11.4    0.212     7\n",
      "   362   14     2    -18.8    0.069     9\n",
      "   365   14     2    -17.7    0.105     0\n",
      "   366   13     2    -18.4    0.060     5\n",
      "   367   13     2    -19.2    0.036     8\n",
      "   376   12     2    -17.4    0.139     0\n",
      "   380   12     2    -17.6    0.096     0\n",
      "   382   11     3     -4.4    0.757     6\n",
      "   383   11     3     -4.0    0.729     9\n",
      "   386   11     5     -4.0    0.566     9\n",
      "   387   11     2    -18.4    0.096     7\n",
      "   388   10     2    -18.4    0.096     0\n",
      "   389   10     6     -4.0    0.902     9\n",
      "   390   10     4     -4.4    0.394     2\n",
      "   391   10     1    -12.5    0.247     9\n",
      "   392   10     2    -18.8    0.036     9\n",
      "   393   10     3     -4.8    0.494     9\n",
      "   394   10     2     -8.1    0.311     9\n",
      "   395   10     3     -4.0    0.559     9\n",
      "   396   10     3     -4.0    0.530     9\n",
      "   397   10     6     -4.0    0.814     9\n",
      "   398   10     4     -3.7    0.431     1\n",
      "   399   10     4     -4.8    0.487     2\n",
      "   400   10     2     -4.4    0.480     8\n",
      "   401   10     4     -4.0    0.924     9\n",
      "   402   10     2     -4.0    0.450     8\n",
      "   403    9     4     -4.4    0.659     7\n",
      "   404    9     6     -4.0    0.711     7\n",
      "   405    9     2    -14.1    0.202     8\n",
      "   406    9     5     -4.0    0.785     8\n",
      "   407    9     5     -4.4    0.596     7\n",
      "   408    9     4     -4.4    0.538     6\n",
      "   409    9     4     -3.7    0.625     0\n",
      "   410    9     5     -4.0    0.952     8\n",
      "   411    9     4     -4.0    0.405     7\n",
      "   412    9     2    -17.8    0.090     0\n",
      "   413    9     5     -4.0    0.940     8\n",
      "   414    9     5     -4.0    0.556     6\n",
      "   415    9     4     -4.4    0.371     8\n",
      "   416    9     3     -6.0    0.446     7\n",
      "   417    9     2    -18.0    0.084     0\n",
      "   418    9     4     -3.8    0.613     1\n",
      "   419    8     5     -4.0    0.479     7\n",
      "   420    8     2    -18.0    0.120     0\n",
      "   421    8     2    -18.4    0.084     0\n",
      "   422    8     6     -4.0    0.544     7\n",
      "   423    8     5     -3.8    0.763     0\n",
      "   424    8     4     -4.0    0.892     7\n",
      "   425    8     2    -19.2    0.048     7\n",
      "   426    8     5     -4.4    0.530     7\n",
      "   427    8     5     -4.0    0.705     7\n",
      "   428    8     3     -6.3    0.367     6\n",
      "   429    8     4     -4.0    0.501     7\n",
      "   430    8     4     -4.4    0.372     6\n",
      "   431    8     2     -4.0    0.542     5\n",
      "   432    8     2    -15.2    0.120     4\n",
      "   433    8     4     -4.4    0.360     7\n",
      "   434    8     5     -3.4    0.607     6\n",
      "   435    7     2    -18.4    0.081     0\n",
      "   436    7     4     -4.4    0.436     5\n",
      "   437    7     5     -4.0    0.663     5\n",
      "   438    7     4     -4.0    0.573     5\n",
      "   439    7     4     -3.4    0.605     0\n",
      "   440    7     4     -4.1    0.670     5\n",
      "   441    7     2    -17.2    0.130     6\n",
      "   442    7     4     -4.0    0.557     6\n",
      "   443    7     2    -18.2    0.060     0\n",
      "   444    7     2    -18.4    0.084     0\n",
      "   445    6     4     -4.4    0.627     4\n",
      "   446    6     6     -4.0    0.940     5\n",
      "   447    6     4     -4.0    0.610     4\n",
      "   448    6     2    -18.0    0.084     0\n",
      "   449    5     3     -4.0    0.551     4\n",
      "   450    5     4     -4.0    0.731     3\n",
      "   451    5     3     -4.0    0.437     3\n",
      "   452    5     5     -4.0    0.514     4\n",
      "   453    5     5     -4.0    0.738     3\n",
      "   454    5     2     -4.0    0.414     3\n",
      "   455    5     5     -4.0    0.575     4\n",
      "   456    5     6     -4.4    0.690     4\n",
      "   457    5     4     -4.1    0.396     3\n",
      "   458    4     4     -4.0    0.436     2\n",
      "   459    4     5     -3.7    0.536     3\n",
      "   460    4     5     -3.7    0.670     0\n",
      "   461    4     5     -4.4    0.524     3\n",
      "   462    4     2    -19.2    0.048     3\n",
      "   463    4     5     -4.4    0.783     3\n",
      "   464    4     2    -15.6    0.157     0\n",
      "   465    4     2    -18.8    0.060     2\n",
      "   466    4     2    -17.6    0.133     0\n",
      "   467    4     2    -18.4    0.084     0\n",
      "   468    4     5     -4.4    0.553     2\n",
      "   469    4     4     -4.0    0.624     3\n",
      "   470    4     6     -4.0    0.930     3\n",
      "   471    4     1     -3.4    0.400     1\n",
      "   472    3     6     -4.0    0.688     2\n",
      "   473    3     4     -4.0    0.659     2\n",
      "   474    3     3     -3.7    0.527     0\n",
      "   475    3     4     -4.0    0.354     2\n",
      "   476    3     2    -19.2    0.024     1\n",
      "   477    3     2     -8.1    0.315     1\n",
      "   478    3     2    -19.2    0.048     0\n",
      "   479    3     2     -5.6    0.337     1\n",
      "   480    3     3     -4.0    0.742     2\n",
      "   481    3     2    -20.0    0.000     0\n",
      "   482    3     3     -5.6    0.494     0\n",
      "   483    3     5     -4.8    0.482     2\n",
      "   484    3     4     -4.0    0.641     2\n",
      "   485    3     2     -4.4    0.345     1\n",
      "   486    2     3     -8.2    0.392     1\n",
      "   487    2     3     -4.4    0.488     0\n",
      "   488    2     2    -13.7    0.226     1\n",
      "   489    2     5     -4.0    0.956     1\n",
      "   490    2     4     -4.8    0.302     1\n",
      "   491    2     5     -4.0    0.865     1\n",
      "   492    2     4     -4.0    0.589     1\n",
      "   493    2     4     -3.7    0.950     0\n",
      "   494    2     2    -16.8    0.096     0\n",
      "   495    1     4     -4.4    0.394     0\n",
      "   496    1     4     -4.4    0.635     0\n",
      "   497    1     2    -19.2    0.048     0\n",
      "   498    1     2    -19.2    0.024     0\n",
      "   499    1     5     -4.0    0.659     0\n",
      "   500    1     4     -4.0    0.463     0\n",
      "   501    1     3    -10.5    0.220     0\n",
      "   502    0     5     -4.0    0.690     0\n",
      "   503    0     4    -18.8    0.060     0\n",
      "   504    0     5     -4.0    0.964     0\n",
      "   505    0     3     -8.2    0.711     0\n",
      "   506    0     2    -20.0    0.000     0\n",
      "   507    0     2    -18.0    0.096     0\n",
      "   508    0     4     -4.8    0.916     0\n",
      "   509    0     5     -4.0    0.964     0\n",
      "   510    0     3    -19.2    0.048     0\n",
      "   511    0     7     -5.2    0.892     0\n",
      "   512    0     4     -4.4    0.940     0\n",
      "   513    0     3    -19.2    0.048     0\n",
      "   514    0     2       --       --     0\n",
      "   515    0     2       --       --     0\n",
      "   516    0     3       --       --     0\n",
      "   517    0     2       --       --     0\n",
      "   518    0     2       --       --     0\n",
      "   519    0     2       --       --     0\n",
      "   520    0     2       --       --     0\n",
      "   521    0     1       --       --     0\n",
      "   522    0     1       --       --     0\n",
      "   523    0     2       --       --     0\n",
      "   524    0     2       --       --     0\n",
      "   525    0     1       --       --     0\n",
      "   526    0     1       --       --     0\n",
      "   527    0     2       --       --     0\n",
      "   528    0     3       --       --     0\n",
      "   529    0     2       --       --     0\n",
      "   530    0     1       --       --     0\n",
      "   531    0     1       --       --     0\n",
      "Total extinctions: 0\n",
      "Generation time: 857.136 sec\n",
      "Population of 539 members in 163 species:\n",
      "   ID   age  size  fitness  adj fit  stag\n",
      "  ====  ===  ====  =======  =======  ====\n",
      "   285   22     3     -3.4    0.536     7\n",
      "   320   17     2    -18.4    0.096     7\n",
      "   324   17     4     -4.0    0.681     9\n",
      "   331   16     4     -4.4    0.635     5\n",
      "   340   15     3     -6.4    0.434     9\n",
      "   342   15     2    -16.7    0.145     0\n",
      "   346   15     4     -4.0    0.786     8\n",
      "   356   14     2    -18.4    0.048     0\n",
      "   361   14     3    -11.4    0.212     7\n",
      "   362   14     2    -18.8    0.069     9\n",
      "   365   14     2    -17.7    0.105     0\n",
      "   366   13     2    -18.4    0.060     5\n",
      "   367   13     2    -19.2    0.036     8\n",
      "   376   12     2    -17.4    0.139     0\n",
      "   380   12     2    -17.6    0.096     0\n",
      "   382   11     3     -4.4    0.757     6\n",
      "   383   11     3     -4.0    0.729     9\n",
      "   386   11     5     -4.0    0.566     9\n",
      "   387   11     2    -18.4    0.096     7\n",
      "   388   10     2    -18.4    0.096     0\n",
      "   389   10     6     -4.0    0.902     9\n",
      "   390   10     4     -4.4    0.394     2\n",
      "   391   10     1    -12.5    0.247     9\n",
      "   392   10     2    -18.8    0.036     9\n",
      "   393   10     3     -4.8    0.494     9\n",
      "   394   10     2     -8.1    0.311     9\n",
      "   395   10     3     -4.0    0.559     9\n",
      "   396   10     3     -4.0    0.530     9\n",
      "   397   10     6     -4.0    0.814     9\n",
      "   398   10     4     -3.7    0.431     1\n",
      "   399   10     4     -4.8    0.487     2\n",
      "   400   10     2     -4.4    0.480     8\n",
      "   401   10     4     -4.0    0.924     9\n",
      "   402   10     2     -4.0    0.450     8\n",
      "   403    9     4     -4.4    0.659     7\n",
      "   404    9     6     -4.0    0.711     7\n",
      "   405    9     2    -14.1    0.202     8\n",
      "   406    9     5     -4.0    0.785     8\n",
      "   407    9     5     -4.4    0.596     7\n",
      "   408    9     4     -4.4    0.538     6\n",
      "   409    9     4     -3.7    0.625     0\n",
      "   410    9     5     -4.0    0.952     8\n",
      "   411    9     4     -4.0    0.405     7\n",
      "   412    9     2    -17.8    0.090     0\n",
      "   413    9     5     -4.0    0.940     8\n",
      "   414    9     5     -4.0    0.556     6\n",
      "   415    9     4     -4.4    0.371     8\n",
      "   416    9     3     -6.0    0.446     7\n",
      "   417    9     2    -18.0    0.084     0\n",
      "   418    9     4     -3.8    0.613     1\n",
      "   419    8     5     -4.0    0.479     7\n",
      "   420    8     2    -18.0    0.120     0\n",
      "   421    8     2    -18.4    0.084     0\n",
      "   422    8     6     -4.0    0.544     7\n",
      "   423    8     5     -3.8    0.763     0\n",
      "   424    8     4     -4.0    0.892     7\n",
      "   425    8     2    -19.2    0.048     7\n",
      "   426    8     5     -4.4    0.530     7\n",
      "   427    8     5     -4.0    0.705     7\n",
      "   428    8     3     -6.3    0.367     6\n",
      "   429    8     4     -4.0    0.501     7\n",
      "   430    8     4     -4.4    0.372     6\n",
      "   431    8     2     -4.0    0.542     5\n",
      "   432    8     2    -15.2    0.120     4\n",
      "   433    8     4     -4.4    0.360     7\n",
      "   434    8     5     -3.4    0.607     6\n",
      "   435    7     2    -18.4    0.081     0\n",
      "   436    7     4     -4.4    0.436     5\n",
      "   437    7     5     -4.0    0.663     5\n",
      "   438    7     4     -4.0    0.573     5\n",
      "   439    7     4     -3.4    0.605     0\n",
      "   440    7     4     -4.1    0.670     5\n",
      "   441    7     2    -17.2    0.130     6\n",
      "   442    7     4     -4.0    0.557     6\n",
      "   443    7     2    -18.2    0.060     0\n",
      "   444    7     2    -18.4    0.084     0\n",
      "   445    6     4     -4.4    0.627     4\n",
      "   446    6     6     -4.0    0.940     5\n",
      "   447    6     4     -4.0    0.610     4\n",
      "   448    6     2    -18.0    0.084     0\n",
      "   449    5     3     -4.0    0.551     4\n",
      "   450    5     4     -4.0    0.731     3\n",
      "   451    5     3     -4.0    0.437     3\n",
      "   452    5     5     -4.0    0.514     4\n",
      "   453    5     5     -4.0    0.738     3\n",
      "   454    5     2     -4.0    0.414     3\n",
      "   455    5     5     -4.0    0.575     4\n",
      "   456    5     6     -4.4    0.690     4\n",
      "   457    5     4     -4.1    0.396     3\n",
      "   458    4     4     -4.0    0.436     2\n",
      "   459    4     5     -3.7    0.536     3\n",
      "   460    4     5     -3.7    0.670     0\n",
      "   461    4     5     -4.4    0.524     3\n",
      "   462    4     2    -19.2    0.048     3\n",
      "   463    4     5     -4.4    0.783     3\n",
      "   464    4     2    -15.6    0.157     0\n",
      "   465    4     2    -18.8    0.060     2\n",
      "   466    4     2    -17.6    0.133     0\n",
      "   467    4     2    -18.4    0.084     0\n",
      "   468    4     5     -4.4    0.553     2\n",
      "   469    4     4     -4.0    0.624     3\n",
      "   470    4     6     -4.0    0.930     3\n",
      "   471    4     1     -3.4    0.400     1\n",
      "   472    3     6     -4.0    0.688     2\n",
      "   473    3     4     -4.0    0.659     2\n",
      "   474    3     3     -3.7    0.527     0\n",
      "   475    3     4     -4.0    0.354     2\n",
      "   476    3     2    -19.2    0.024     1\n",
      "   477    3     2     -8.1    0.315     1\n",
      "   478    3     2    -19.2    0.048     0\n",
      "   479    3     2     -5.6    0.337     1\n",
      "   480    3     3     -4.0    0.742     2\n",
      "   481    3     2    -20.0    0.000     0\n",
      "   482    3     3     -5.6    0.494     0\n",
      "   483    3     5     -4.8    0.482     2\n",
      "   484    3     4     -4.0    0.641     2\n",
      "   485    3     2     -4.4    0.345     1\n",
      "   486    2     3     -8.2    0.392     1\n",
      "   487    2     3     -4.4    0.488     0\n",
      "   488    2     2    -13.7    0.226     1\n",
      "   489    2     5     -4.0    0.956     1\n",
      "   490    2     4     -4.8    0.302     1\n",
      "   491    2     5     -4.0    0.865     1\n",
      "   492    2     4     -4.0    0.589     1\n",
      "   493    2     4     -3.7    0.950     0\n",
      "   494    2     2    -16.8    0.096     0\n",
      "   495    1     4     -4.4    0.394     0\n",
      "   496    1     4     -4.4    0.635     0\n",
      "   497    1     2    -19.2    0.048     0\n",
      "   498    1     2    -19.2    0.024     0\n",
      "   499    1     5     -4.0    0.659     0\n",
      "   500    1     4     -4.0    0.463     0\n",
      "   501    1     3    -10.5    0.220     0\n",
      "   502    0     5     -4.0    0.690     0\n",
      "   503    0     4    -18.8    0.060     0\n",
      "   504    0     5     -4.0    0.964     0\n",
      "   505    0     3     -8.2    0.711     0\n",
      "   506    0     2    -20.0    0.000     0\n",
      "   507    0     2    -18.0    0.096     0\n",
      "   508    0     4     -4.8    0.916     0\n",
      "   509    0     5     -4.0    0.964     0\n",
      "   510    0     3    -19.2    0.048     0\n",
      "   511    0     7     -5.2    0.892     0\n",
      "   512    0     4     -4.4    0.940     0\n",
      "   513    0     3    -19.2    0.048     0\n",
      "   514    0     2       --       --     0\n",
      "   515    0     2       --       --     0\n",
      "   516    0     3       --       --     0\n",
      "   517    0     2       --       --     0\n",
      "   518    0     2       --       --     0\n",
      "   519    0     2       --       --     0\n",
      "   520    0     2       --       --     0\n",
      "   521    0     1       --       --     0\n",
      "   522    0     1       --       --     0\n",
      "   523    0     2       --       --     0\n",
      "   524    0     2       --       --     0\n",
      "   525    0     1       --       --     0\n",
      "   526    0     1       --       --     0\n",
      "   527    0     2       --       --     0\n",
      "   528    0     3       --       --     0\n",
      "   529    0     2       --       --     0\n",
      "   530    0     1       --       --     0\n",
      "   531    0     1       --       --     0\n",
      "Total extinctions: 0\n",
      "Generation time: 857.137 sec\n",
      "Saving checkpoint to neat-checkpoint-v02-48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ****** Running generation 49 ****** \n",
      "\n",
      "\n",
      " ****** Running generation 49 ****** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start the game\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "\n",
    "# # OPTIONAL\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "\n",
    "    global num_episodes, timesteps_per_episode, current_episode, current_timestep, min_reward\n",
    "\n",
    "    # FOR EACH GENOME\n",
    "    for genome_id, genome in genomes:\n",
    "               \n",
    "        # generate the neural network based on the config provided\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    \n",
    "        # define the initial fitness of the genome\n",
    "        genome.fitness = 0.0\n",
    "    \n",
    "        # define episodes rewards (list) idea is to keep the fitness scores of all episodes and take the max\n",
    "        episodes_rewards = []\n",
    "        \n",
    "        # FOR EACH EPISODE\n",
    "        for episode in range(num_episodes):\n",
    "            \n",
    "            # Episode reward = 0  \n",
    "            ep_reward = 0\n",
    "            \n",
    "            # reset the game state to the initial phase\n",
    "            initial_state = env.reset()\n",
    "\n",
    "            # map inputs suitable for the Neural Network (initial state of the game as flatten array, e.g. with length 49, created by the initial 7x7 grid)\n",
    "            # used as an input layer in the Neural Network\n",
    "            initial_inputs = process_state(initial_state)\n",
    "            \n",
    "            game_state_after_step = initial_inputs\n",
    "            \n",
    "            # FOR EACH STEP\n",
    "            for step in range(timesteps_per_episode):\n",
    "                \n",
    "               \n",
    "                # calculate probabilities for each output to be selected\n",
    "                action_prob = net.activate(game_state_after_step)\n",
    "                \n",
    "                # select the action, based on the output's probabilities of being selected\n",
    "                action = map_action(action_prob)\n",
    "                \n",
    "                # ADD CUSTOM MUTATION IN THE STEPS (at a random event, the alg could chose a random step)\n",
    "                \n",
    "                if random.random() < epsilon:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # select the action, based on the output's probabilities of being selected\n",
    "                    action = map_action(action_prob)\n",
    "                \n",
    "#                 # RANDOM ACTION (replace with the genome)\n",
    "#                 action = env.action_space.sample()\n",
    "\n",
    "                # make the move in the game and output game state + info + reward\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                \n",
    "#                 # TODO (MAYBE) !!!! Adjust the fitness function\n",
    "                \n",
    "#                 # 1) USE THE info to extract information about the move and change the reward accordingly\n",
    "                \n",
    "                # penalizes the passiveness of the player; rewards movement of boxes more\n",
    "                if not info[\"action.moved_player\"]:\n",
    "                    reward = -0.5                \n",
    "                elif info[\"action.moved_box\"]:\n",
    "                    reward = 0.2\n",
    "#                 elif ....\n",
    "                \n",
    "                game_state_after_step = process_observation(environment=env, obs=observation)\n",
    "\n",
    "                # IMAGE STUFF\n",
    "                image = env.render(mode='rgb_array')\n",
    "                viewer.render(image)\n",
    "\n",
    "#                 # PRINT INFO\n",
    "                logging.info(f'Population\\'s steps info: {(ACTION_LOOKUP[action], reward, done, info)}')\n",
    "\n",
    "                # POPULATE THE Episode reward +=\n",
    "                # if the game didn't end on this step\n",
    "                if not done:\n",
    "                    ep_reward += reward\n",
    "                    current_timestep += 1\n",
    "                    \n",
    "                # if the game ended\n",
    "                else:\n",
    "#                     current_timestep = 0\n",
    "#                     current_episode += 1\n",
    "                    print(f\"I BEAT THE STUPID GAME!!! Happend on step {current_timestep}\")\n",
    "                    break\n",
    "    \n",
    "                    # OR BREAK\n",
    "\n",
    "            # add the accumulated rewards for this episode into a list (episodes_rewards)   \n",
    "            episodes_rewards.append(ep_reward)\n",
    "\n",
    "        # choose the best performance on an episode for the genome\n",
    "        genome.fitness = max(episodes_rewards)\n",
    "\n",
    "#         print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "        \n",
    "\n",
    "\n",
    "# Run until a solution is found. The number indicates the max number of generations to be produced\n",
    "winner = p.run(eval_genomes, 25)\n",
    "\n",
    "\n",
    "# Display the winning genome.\n",
    "print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# SAVE THE WINNER GENOME\n",
    "with open(\"winner.pkl\", \"wb\") as f:\n",
    "    pickle.dump(winner, f)\n",
    "\n",
    "# Show output of the most fit genome against training data.\n",
    "print('\\nOutput:')\n",
    "winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "# Save the winner\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(winner, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6082cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T05:34:06.853784Z",
     "start_time": "2024-06-28T05:34:06.061859Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize.plot_stats(stats, ylog=False, view=True)\n",
    "visualize.plot_species(stats, view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14ed26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T06:37:58.613943Z",
     "start_time": "2024-06-28T06:37:58.404149Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize.draw_net(config=config, genome=winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de306002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674e73a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086be0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca1de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b4952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daca4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180f5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238db659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b127d1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b519dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e834c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53154976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6709c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a3735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:37:55.958605Z",
     "start_time": "2024-06-27T16:37:55.936867Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "\n",
    "# Load configuration.\n",
    "config_filename = 'config-feedforward_v01'\n",
    "config = neat.Config(neat.DefaultGenome, \n",
    "                     neat.DefaultReproduction, \n",
    "                     neat.DefaultSpeciesSet, \n",
    "                     neat.DefaultStagnation, \n",
    "                     config_filename)\n",
    "\n",
    "config.genome_config.add_node_mutation_prob = 0.03\n",
    "config.genome_config.add_connection_mutation_prob = 0.05\n",
    "\n",
    "# Print the parsed parameters to debug\n",
    "print(\"Initial connection type:\", config.genome_config.initial_connection)\n",
    "print(\"Allowed connectivity options:\", config.genome_config.allowed_connectivity)\n",
    "print(\"Activation options:\", config.genome_config.activation_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393643a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c937403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30815687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7995ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1ed23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ded82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae5223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ce5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4eb568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d191f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646a9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91215838",
   "metadata": {},
   "source": [
    "### ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8599",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-26T13:39:04.976Z"
    }
   },
   "outputs": [],
   "source": [
    "import neat\n",
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import logging\n",
    "from neat.reporting import StdOutReporter\n",
    "\n",
    "# Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='neat_log.txt', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# Custom reporter class\n",
    "class CustomReporter(StdOutReporter):\n",
    "    def __init__(self, show_species_detail):\n",
    "        super().__init__(show_species_detail)\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def end(self):\n",
    "        runtime = time.time() - self.start_time\n",
    "        logging.info(f'Total runtime: {runtime:.2f} seconds')\n",
    "\n",
    "    def post_evaluate(self, config, population, species_set, best_genome):\n",
    "        super().post_evaluate(config, population, species_set, best_genome)\n",
    "        \n",
    "        # Log population's average fitness\n",
    "        total_fitness = sum(genome.fitness for genome in population.values())\n",
    "        avg_fitness = total_fitness / len(population)\n",
    "        logging.info(f'Population\\'s average fitness: {avg_fitness}')\n",
    "        \n",
    "        # Log adjusted fitness score\n",
    "        adjusted_fitness = []\n",
    "        for species_id, species in species_set.species.items():\n",
    "            for genome_id in species.members:\n",
    "                genome = population[genome_id]\n",
    "                adjusted_fitness.append(genome.fitness / len(species.members))\n",
    "        avg_adjusted_fitness = sum(adjusted_fitness) / len(adjusted_fitness)\n",
    "        logging.info(f'Population\\'s average adjusted fitness: {avg_adjusted_fitness}')\n",
    "        \n",
    "        # Log best genome information\n",
    "        logging.info(f'\\nBest genome:\\nKey: {best_genome.key}\\nFitness: {best_genome.fitness}')\n",
    "        logging.info(f'Nodes:')\n",
    "        for node_key, node in best_genome.nodes.items():\n",
    "            logging.info(f'\\t{node_key} {node}')\n",
    "        logging.info(f'Connections:')\n",
    "        for conn_key, conn in best_genome.connections.items():\n",
    "            logging.info(f'\\t{conn_key} {conn}')\n",
    "        logging.info(f'Timestamp: {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "\n",
    "def process_observation(environment, obs):\n",
    "    # Convert the observation to RGB frame or custom observation\n",
    "    arr_walls, arr_goals, arr_boxes, arr_player = environment.render(mode='raw')\n",
    "\n",
    "    # Initialize the combined array with walls (1s)\n",
    "    combined = np.ones_like(arr_walls)\n",
    "    \n",
    "    # Set empty fields (0s)\n",
    "    combined[arr_walls == 0] = 0\n",
    "    \n",
    "    # Set targets (3s)\n",
    "    combined[arr_goals == 1] = 3\n",
    "    \n",
    "    # Set boxes (2s)\n",
    "    combined[arr_boxes == 1] = 2\n",
    "    \n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(arr_boxes == 1) & (arr_goals == 1)] = 4\n",
    "    \n",
    "    # Set player position (5s)\n",
    "    combined[arr_player == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "    return flat_array\n",
    "\n",
    "\n",
    "def process_state(state):\n",
    "    # Processes the initial state of env.reset()\n",
    "\n",
    "    # Initialize the combined array with walls (0s)\n",
    "    combined = np.ones_like(state[0])\n",
    "    \n",
    "    # Set empty fields (1s)\n",
    "    combined[state[0] == 0] = 0\n",
    "\n",
    "    # Set targets (3s)\n",
    "    combined[state[1] == 1] = 3\n",
    "\n",
    "    # Set boxes (2s)\n",
    "    combined[state[2] == 1] = 2\n",
    "\n",
    "    # Set boxes on targets (4s)\n",
    "    combined[(state[2] == 1) & (state[1] == 1)] = 4\n",
    "\n",
    "    # Set player position (5s)\n",
    "    combined[state[3] == 1] = 5\n",
    "\n",
    "    # Flatten the array\n",
    "    flat_array = combined.flatten()\n",
    "    \n",
    "    return flat_array\n",
    "\n",
    "\n",
    "# Start the game\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "env.reset()\n",
    "\n",
    "# Optional viewer setup\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "def map_action(action_prob):\n",
    "    return np.argmax(action_prob)\n",
    "\n",
    "def eval_genomes(genomes, config):\n",
    "    global num_episodes, timesteps_per_episode\n",
    "\n",
    "    # For each genome\n",
    "    for genome_id, genome in genomes:\n",
    "        # Generate the neural network based on the config provided\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    \n",
    "        # Define the initial fitness of the genome\n",
    "        genome.fitness = 0.0\n",
    "    \n",
    "        # Define episodes rewards (list) idea is to keep the fitness scores of all episodes and take the max\n",
    "        episodes_rewards = []\n",
    "        \n",
    "        # For each episode\n",
    "        for episode in range(num_episodes):\n",
    "            # Episode reward = 0  \n",
    "            ep_reward = 0\n",
    "            \n",
    "            # Reset the game state to the initial phase\n",
    "            initial_state = env.reset()\n",
    "\n",
    "            # Map inputs suitable for the Neural Network (initial state of the game as flatten array, e.g. with length 49, created by the initial 7x7 grid)\n",
    "            # Used as an input layer in the Neural Network\n",
    "            initial_inputs = process_state(initial_state)\n",
    "            \n",
    "            game_state_after_step = initial_inputs\n",
    "            \n",
    "            # For each step\n",
    "            for step in range(timesteps_per_episode):\n",
    "                # Calculate probabilities for each output to be selected\n",
    "                action_prob = net.activate(game_state_after_step)\n",
    "                \n",
    "                # Select the action, based on the output's probabilities of being selected\n",
    "                action = map_action(action_prob)\n",
    "                \n",
    "                # Make the move in the game and output game state + info + reward\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                \n",
    "                game_state_after_step = process_observation(environment=env, obs=observation)\n",
    "\n",
    "                # Image stuff\n",
    "                image = env.render(mode='rgb_array')\n",
    "                viewer.render(image)\n",
    "\n",
    "                # Print info\n",
    "                print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "                # Populate the episode reward\n",
    "                if not done:\n",
    "                    ep_reward += reward\n",
    "                else:\n",
    "                    print(f\"Game finished in {step+1} steps\")\n",
    "                    break\n",
    "    \n",
    "            # Add the accumulated rewards for this episode into a list (episodes_rewards)   \n",
    "            episodes_rewards.append(ep_reward)\n",
    "\n",
    "        # Choose the best performance on an episode for the genome\n",
    "        genome.fitness = max(episodes_rewards)\n",
    "\n",
    "        print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "\n",
    "# Load configuration.\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     'config-feedforward')\n",
    "\n",
    "# Create the population, which is the top-level object for a NEAT run.\n",
    "p = neat.Population(config)\n",
    "\n",
    "# Add a stdout reporter to show progress in the terminal.\n",
    "p.add_reporter(neat.StdOutReporter(True))\n",
    "p.add_reporter(CustomReporter(True))\n",
    "p.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "# Run until a solution is found. The number indicates the max number of generations to be produced\n",
    "winner = p.run(eval_genomes, 5)\n",
    "\n",
    "# Display the winning genome.\n",
    "print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# Show output of the most fit genome against training data.\n",
    "print('\\nOutput:')\n",
    "winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "# Start the Pyglet event loop to keep the window open\n",
    "pyglet.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1539b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98769e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4aca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9424f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e221f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325e476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525257b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23999afe",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd48847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the game\n",
    "\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "\n",
    "# # OPTIONAL\n",
    "\n",
    "# viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "\n",
    "# ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 1\n",
    "timesteps_per_episode = 40\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "min_reward = -10\n",
    "\n",
    "\n",
    "def eval_genomes(genomes, config)\n",
    "# FOR EACH GENOME\n",
    "    for genome_id, genome in genomes:\n",
    "        \n",
    "        env = gym.make()\n",
    "    # net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    # DEF INITIAL GENOME FITNESS = 0\n",
    "    \n",
    "    \n",
    "    # EPISODES REWARDS = [] IDEA IS TO KEEP THE FITNESS SCORES OF ALL EPISODES AND THEN TAKE THE MAX\n",
    "    \n",
    "    # FOR EACH EPISODE\n",
    "        # Episode reward = 0  \n",
    "        # env.reset()\n",
    "            \n",
    "        # FOR EACH STEP\n",
    "            # ACTION - GENERATED BY THE GENOME\n",
    "            # RANDOM ACTION\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "            # MAKE THE MOVE IN THE GAME\n",
    "            # OUTPUT GAME STATE AFTER THE STEP WITH INFO + REWARD            \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            # IMAGE STUFF\n",
    "            image = env.render(mode='rgb_array')\n",
    "            viewer.render(image)\n",
    "            \n",
    "            # PRINT INFO\n",
    "            print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "            # POPULATE THE Episode reward +=\n",
    "            # if not done:\n",
    "                # reward += MIN REWARD\n",
    "                # current_timestep += 1\n",
    "\n",
    "            # if done:\n",
    "                # current_timestep = 0\n",
    "                # current_episode += 1\n",
    "\n",
    "                # OR BREAK\n",
    "\n",
    "        # EPISODES REWARDS APPEND episode reward   \n",
    "        \n",
    "    \n",
    "    # GENOME.FITNESS = max(EPISODE REWARDS)        \n",
    "                \n",
    "\n",
    "        \n",
    "\n",
    "# # Load configuration.\n",
    "# config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "#                      neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "#                      'config-feedforward')\n",
    "\n",
    "# # Create the population, which is the top-level object for a NEAT run.\n",
    "# p = neat.Population(config)\n",
    "\n",
    "# # Add a stdout reporter to show progress in the terminal.\n",
    "# p.add_reporter(neat.StdOutReporter(False))\n",
    "\n",
    "# # Run until a solution is found.\n",
    "# winner = p.run(eval_genomes, 5)\n",
    "\n",
    "# # Display the winning genome.\n",
    "# print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# # Show output of the most fit genome against training data.\n",
    "# print('\\nOutput:')\n",
    "# winner_net = neat.nn.FeedForwardNetwork.create(winner, config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752210af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c83cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90653981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932315a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82e8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a46f3fa4",
   "metadata": {},
   "source": [
    "### Game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c18863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_sokoban\n",
    "import pyglet\n",
    "from pyglet import clock\n",
    "import numpy as np\n",
    "\n",
    "## Custom rendering setup if gym's rendering is not available\n",
    "class Viewer:\n",
    "    def __init__(self, width, height):\n",
    "        self.window = pyglet.window.Window(width, height)\n",
    "        self.image = None\n",
    "        self.window.on_draw = self.on_draw\n",
    "\n",
    "    def render(self, image):\n",
    "        self.image = pyglet.image.ImageData(image.shape[1], image.shape[0], 'RGB', image.tobytes(), pitch=image.shape[1] * -3)\n",
    "        self.window.dispatch_event('on_draw')\n",
    "\n",
    "    def on_draw(self):\n",
    "        if self.image:\n",
    "            self.window.clear()\n",
    "            self.image.blit(0, 0)\n",
    "\n",
    "env = gym.make('Sokoban-small-v1')\n",
    "# generate the level in the initial stage (env.reset) \n",
    "env.reset()\n",
    "\n",
    "print(\"Room Fixed\")\n",
    "print(env.room_fixed)\n",
    "print(type(env.room_fixed))\n",
    "print(env.room_fixed.shape)\n",
    "print()\n",
    "print(env.room_state)\n",
    "print()\n",
    "print(env.box_mapping)\n",
    "print()\n",
    "\n",
    "\n",
    "viewer = Viewer(160, 160)  # Adjust the size according to your environment\n",
    "\n",
    "ACTION_LOOKUP = env.unwrapped.get_action_lookup()\n",
    "\n",
    "# Define episode and timestep parameters\n",
    "num_episodes = 2\n",
    "timesteps_per_episode = 100\n",
    "\n",
    "current_episode = 0\n",
    "current_timestep = 0\n",
    "\n",
    "def update_environment(dt):\n",
    "    global current_episode, current_timestep, num_episodes, timesteps_per_episode\n",
    "\n",
    "    if current_episode < num_episodes:\n",
    "        if current_timestep < timesteps_per_episode:\n",
    "            # RANDOM ACTION\n",
    "            action = env.action_space.sample()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            \n",
    "            image = env.render(mode='rgb_array')\n",
    "            viewer.render(image)\n",
    "\n",
    "            print(ACTION_LOOKUP[action], reward, done, info)\n",
    "\n",
    "            if done:\n",
    "                print(f\"Episode finished after {current_timestep + 1} timesteps\")\n",
    "                current_timestep = 0\n",
    "                current_episode += 1\n",
    "                env.reset()\n",
    "            else:\n",
    "                current_timestep += 1\n",
    "        else:\n",
    "            current_episode += 1\n",
    "            current_timestep = 0\n",
    "            env.reset()\n",
    "    else:\n",
    "        print(\"All episodes finished. Closing window.\")\n",
    "        viewer.window.close()  # Close the Pyglet window explicitly\n",
    "\n",
    "# Increase the frequency to match rendering needs (e.g., 60Hz)\n",
    "clock.schedule_interval(update_environment, 1/60.0)\n",
    "\n",
    "pyglet.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6a928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b6ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db59de40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb8309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neat_test]",
   "language": "python",
   "name": "conda-env-.conda-neat_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
